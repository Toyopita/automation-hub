#!/usr/bin/env python3
"""
Relationship Engine - Modular relationship management for autonomous LINE bots.

Provides 7 core components:
1. ProfileLearner  - Continuous profile building from conversations
2. StrategyEngine  - Decision-making based on stage, emotion, budget
3. StageManager    - Relationship stage tracking and transitions
4. PersonaAdapter  - Adaptive prompt construction
5. TimingController - Human-like response timing
6. ProactiveScheduler - Natural conversation initiation
7. MultiPersonBudget  - Budget allocation across multiple persons
"""

import asyncio
import json
import logging
import os
import random
import re
import tempfile
from collections import deque
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any
from zoneinfo import ZoneInfo

logger = logging.getLogger('relationship_engine')

BASE_DIR = Path(__file__).parent
CLAUDE_CLI = '/Users/minamitakeshi/.local/bin/claude'
DEFAULT_MODEL = 'claude-sonnet-4-5-20250929'
JST = ZoneInfo('Asia/Tokyo')


# ============================================================
# Utility: Claude CLI invocation
# ============================================================
async def _call_claude_cli(prompt: str, system_prompt: str, model: str = DEFAULT_MODEL,
                           timeout: float = 90.0) -> str:
    """Run Claude CLI in /tmp and return raw stdout text."""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False,
                                     encoding='utf-8', dir='/tmp') as f:
        f.write(prompt)
        tmp_path = f.name

    try:
        proc = await asyncio.create_subprocess_exec(
            '/bin/bash', '-c',
            f'cd /tmp && cat "{tmp_path}" | {CLAUDE_CLI} --print --model {model} '
            f'--system-prompt "{system_prompt}"',
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=timeout)
    finally:
        try:
            os.unlink(tmp_path)
        except OSError:
            pass

    output = stdout.decode('utf-8').strip()
    if not output:
        raise RuntimeError(f"Claude CLI returned empty output. stderr: {stderr.decode()[:300]}")
    return output


def _extract_json(text: str) -> dict:
    """Extract JSON object from Claude CLI output that may contain markdown fences."""
    if '```json' in text:
        text = text.split('```json')[1].split('```')[0].strip()
    elif '```' in text:
        text = text.split('```')[1].split('```')[0].strip()

    idx = text.find('{')
    if idx >= 0:
        text = text[idx:]
        ridx = text.rfind('}')
        if ridx >= 0:
            text = text[:ridx + 1]

    return json.loads(text)


async def _call_claude_json(prompt: str, system_prompt: str, model: str = DEFAULT_MODEL,
                            retries: int = 3) -> dict:
    """Call Claude CLI and parse JSON response with retries."""
    last_error = None
    for attempt in range(retries):
        try:
            raw = await _call_claude_cli(prompt, system_prompt, model)
            return _extract_json(raw)
        except Exception as e:
            last_error = e
            logger.warning(f"Claude CLI attempt {attempt + 1}/{retries} failed: {e}")
            if attempt < retries - 1:
                await asyncio.sleep(2)
    raise RuntimeError(f"All {retries} Claude CLI attempts failed: {last_error}")


# ============================================================
# Utility: Atomic JSON file I/O
# ============================================================
def _load_json(path: Path, default: Any = None) -> Any:
    """Load JSON file, returning default if missing or corrupt."""
    if not path.exists():
        return default if default is not None else {}
    try:
        return json.loads(path.read_text(encoding='utf-8'))
    except Exception as e:
        logger.warning(f"Failed to load {path}: {e}")
        return default if default is not None else {}


def _save_json(path: Path, data: Any):
    """Atomic JSON write: write to .tmp then rename."""
    tmp_path = path.with_suffix('.tmp')
    try:
        tmp_path.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding='utf-8'
        )
        tmp_path.replace(path)
    except Exception as e:
        logger.error(f"Failed to save {path}: {e}")
        try:
            tmp_path.unlink(missing_ok=True)
        except OSError:
            pass
        raise


# ============================================================
# Data file path helpers
# ============================================================
def _profile_path(name: str) -> Path:
    return BASE_DIR / f'{name}_profile.json'


def _relationship_path(name: str) -> Path:
    return BASE_DIR / f'{name}_relationship.json'


def _default_profile(display_name: str) -> dict:
    """Create a default v2 profile."""
    return {
        "version": 2,
        "name": display_name,
        "last_updated": datetime.now(JST).isoformat(),
        "facts": {
            "age": None,
            "location": None,
            "occupation": None,
            "hobbies": [],
            "family": [],
            "languages": [],
            "favorites": {"food": [], "music": [], "movies": [], "activities": []},
            "schedule": {"typical_active_hours": [], "work_schedule": None, "timezone_confirmed": False},
            "important_dates": [],
            "misc_facts": []
        },
        "personality": {
            "introversion": 5, "emotional_expressiveness": 5,
            "humor_appreciation": 5, "adventurousness": 5,
            "confidence": 5, "warmth": 5, "observations": []
        },
        "communication_style": {
            "avg_message_length": None, "emoji_frequency": "unknown",
            "preferred_emojis": [], "formality_level": "unknown",
            "humor_style": None, "response_speed_tendency": None,
            "response_time_avg_minutes": None, "active_hours": [],
            "conversation_starters_used": [], "vocabulary_level": "unknown",
            "grammar_patterns": []
        },
        "topic_engagement": {},
        "effective_patterns": [],
        "avoid_patterns": [],
        "ng_topics": [],
        "temporal_patterns": {
            "most_active_day": None, "most_active_hour": None,
            "avg_conversation_length_messages": None, "initiates_ratio": None
        }
    }


def _default_relationship(display_name: str) -> dict:
    """Create a default v2 relationship state."""
    today = datetime.now(JST).strftime('%Y-%m-%d')
    return {
        "version": 2,
        "stage": "friends",
        "stage_history": [{"stage": "friends", "entered": today, "exited": None}],
        "started": today,
        "signals": {
            "positive": {"total_score": 0, "recent_7d": [], "history": []},
            "negative": {"total_score": 0, "recent_7d": [], "history": []}
        },
        "transition_readiness": {
            "days_in_stage": 0,
            "consecutive_positive_days": 0,
            "last_risk_event": None,
            "blocked_until": None
        },
        "push_pull": {
            "recent_initiators": [],
            "your_question_count": 0,
            "her_question_count": 0,
            "balance_score": 0.5
        },
        "topic_history": [],
        "total_exchanges": 0,
        "total_days_active": 0,
        "notes": []
    }


# ============================================================
# 1. ProfileLearner
# ============================================================
class ProfileLearner:
    """Continuously build and refine a model of the person from every conversation exchange."""

    PROFILE_UPDATE_PROMPT = """Analyze this conversation exchange and extract learnings about {display_name}.

Current known profile:
{current_profile_json}

Recent conversation:
{messages}

Extract and return JSON:
{{
  "new_facts": [
    {{"category": "hobby", "fact": "likes cooking", "confidence": 0.8, "source_quote": "I made pasta today", "tags": ["cooking", "food", "hobby", "kitchen", "pasta", "cuisine"]}}
  ],
  "personality_updates": {{
    "warmth": {{"value": 7, "evidence": "uses lots of affectionate language"}}
  }},
  "communication_observations": {{
    "emoji_frequency": "moderate (2-3 per message)",
    "avg_length": "1-2 sentences",
    "preferred_emojis": ["üòÇ", "ü•∫"],
    "formality_level": "casual",
    "new_vocabulary": ["ngl", "lowkey"],
    "humor_style": "playful teasing and self-deprecating",
    "response_speed_tendency": "fast (under 5 min) when engaged, slow (30+ min) when busy"
  }},
  "topic_engagement": {{
    "food": 8,
    "music": 6,
    "work": 3
  }},
  "ng_topics": [
    {{"topic": "politics", "reason": "changed subject quickly, seemed uncomfortable", "confidence": 0.7}}
  ],
  "effective_patterns": [
    {{"pattern": "sharing_music", "engagement_boost": 2.3, "evidence": "responded with long excited message"}}
  ],
  "avoid_patterns": [
    {{"pattern": "too_many_questions", "engagement_drop": -1.2, "evidence": "gave short answers when asked 3 questions"}}
  ],
  "signals": [
    {{"type": "positive", "signal": "asks_personal_questions", "evidence": "asked about your family"}}
  ]
}}

Rules:
- Only include facts you are confident about (confidence >= 0.5)
- Do not repeat facts already in the profile
- If no new information, return empty arrays/objects
- For each new_fact, include a "tags" array with 5-10 topic tags. Include synonyms, related terms, and broader categories. Example: a fact about "works at Indonesian restaurant" should have tags like ["work", "job", "occupation", "restaurant", "Indonesian", "food", "service", "employment", "hospitality", "cuisine"]
- For humor_style: describe how she uses humor (e.g. sarcastic, playful, dry, self-deprecating, meme-based, or "rarely uses humor")
- For response_speed_tendency: note if she replies fast/slow and under what conditions
- For ng_topics: topics where she showed discomfort, disengagement, or negative reaction
- For effective/avoid_patterns: what conversation approaches worked well or poorly
- Return ONLY valid JSON, no markdown"""

    SYSTEM_PROMPT = ("You are a relationship intelligence analyst. "
                     "Extract factual information from conversations. "
                     "Return ONLY valid JSON. Be precise and evidence-based.")

    async def learn_from_exchange(self, messages_in: list[str], message_out: str,
                                  config: dict) -> dict:
        """Analyze a conversation exchange and update the person's profile.

        Args:
            messages_in: List of incoming messages from the person.
            message_out: The bot's response message.
            config: Person config dict (must have 'name', 'display_name').

        Returns:
            The Claude analysis result dict.
        """
        name = config['name']
        display_name = config.get('display_name', name)
        model = config.get('claude_model', DEFAULT_MODEL)

        profile = self.load_profile(name, display_name)

        # Build conversation text
        conv_lines = []
        for m in messages_in:
            conv_lines.append(f"{display_name}: {m}")
        if message_out:
            conv_lines.append(f"You: {message_out}")
        messages_text = "\n".join(conv_lines)

        prompt = self.PROFILE_UPDATE_PROMPT.format(
            display_name=display_name,
            current_profile_json=json.dumps(profile, ensure_ascii=False, indent=2),
            messages=messages_text
        )

        try:
            result = await _call_claude_json(prompt, self.SYSTEM_PROMPT, model=model)
        except Exception as e:
            logger.error(f"Profile learning failed for {name}: {e}")
            return {}

        self._merge_updates(profile, result)
        profile['last_updated'] = datetime.now(JST).isoformat()
        self.save_profile(name, profile)
        logger.info(f"Profile updated for {name}: {len(result.get('new_facts', []))} new facts")
        return result

    def load_profile(self, name: str, display_name: str = '') -> dict:
        """Load profile, creating default if it doesn't exist."""
        path = _profile_path(name)
        profile = _load_json(path)
        if not profile or profile.get('version') != 2:
            profile = _default_profile(display_name or name)
            _save_json(path, profile)
        return profile

    def save_profile(self, name: str, profile: dict):
        _save_json(_profile_path(name), profile)

    def _merge_updates(self, profile: dict, updates: dict):
        """Merge Claude's analysis results into the existing profile."""
        # Merge new facts
        for fact in updates.get('new_facts', []):
            category = fact.get('category', 'misc_facts')
            fact_text = fact.get('fact', '')
            if not fact_text:
                continue

            facts = profile.get('facts', {})
            if category in ('hobby', 'hobbies'):
                hobbies = facts.get('hobbies', [])
                if fact_text not in hobbies:
                    hobbies.append(fact_text)
                    facts['hobbies'] = hobbies
            elif category == 'family':
                family = facts.get('family', [])
                if fact_text not in family:
                    family.append(fact_text)
                    facts['family'] = family
            elif category in ('food', 'music', 'movies', 'activities'):
                favorites = facts.get('favorites', {})
                lst = favorites.get(category, [])
                if fact_text not in lst:
                    lst.append(fact_text)
                    favorites[category] = lst
                facts['favorites'] = favorites
            elif category in ('age', 'location', 'occupation'):
                facts[category] = fact_text
            else:
                misc = facts.get('misc_facts', [])
                # Check for duplicates (handle both str and dict formats)
                existing_texts = set()
                for f in misc:
                    if isinstance(f, dict):
                        existing_texts.add(f.get('text', ''))
                    elif isinstance(f, str):
                        existing_texts.add(f)
                if fact_text not in existing_texts:
                    tags = fact.get('tags', [])
                    misc.append({
                        'text': fact_text,
                        'tags': tags,
                        'added': datetime.now(JST).strftime('%Y-%m-%d')
                    })
                    facts['misc_facts'] = misc
            profile['facts'] = facts

        # Merge personality updates
        for trait, info in updates.get('personality_updates', {}).items():
            if trait in profile.get('personality', {}):
                if isinstance(info, dict):
                    profile['personality'][trait] = info.get('value', profile['personality'][trait])
                    evidence = info.get('evidence', '')
                    if evidence:
                        observations = profile['personality'].get('observations', [])
                        observations.append(f"{trait}: {evidence}")
                        # Keep last 20 observations
                        profile['personality']['observations'] = observations[-20:]
                elif isinstance(info, (int, float)):
                    profile['personality'][trait] = info

        # Merge communication observations
        comm_obs = updates.get('communication_observations', {})
        comm = profile.get('communication_style', {})
        if comm_obs.get('emoji_frequency'):
            comm['emoji_frequency'] = comm_obs['emoji_frequency']
        if comm_obs.get('avg_length'):
            comm['avg_message_length'] = comm_obs['avg_length']
        if comm_obs.get('preferred_emojis'):
            existing_emojis = comm.get('preferred_emojis', [])
            for e in comm_obs['preferred_emojis']:
                if e not in existing_emojis:
                    existing_emojis.append(e)
            comm['preferred_emojis'] = existing_emojis[-15:]
        if comm_obs.get('formality_level'):
            comm['formality_level'] = comm_obs['formality_level']
        if comm_obs.get('humor_style'):
            comm['humor_style'] = comm_obs['humor_style']
        if comm_obs.get('response_speed_tendency'):
            comm['response_speed_tendency'] = comm_obs['response_speed_tendency']
        if comm_obs.get('new_vocabulary'):
            patterns = comm.get('grammar_patterns', [])
            for v in comm_obs['new_vocabulary']:
                if v not in patterns:
                    patterns.append(v)
            comm['grammar_patterns'] = patterns[-30:]
        profile['communication_style'] = comm

        # Merge topic engagement scores
        for topic, score in updates.get('topic_engagement', {}).items():
            existing = profile.get('topic_engagement', {})
            # Normalize score: extract number from dict if needed
            if isinstance(score, dict):
                score = score.get('interest', 5)
            if score is None:
                score = 5
            # Normalize existing value
            old_val = existing.get(topic)
            if isinstance(old_val, dict):
                old_val = old_val.get('interest')
            # Weighted average if topic already exists
            if old_val is not None:
                existing[topic] = round((old_val * 0.6 + score * 0.4), 1)
            else:
                existing[topic] = score
            profile['topic_engagement'] = existing

        # Merge NG topics
        for ng in updates.get('ng_topics', []):
            topic = ng.get('topic', '')
            if not topic:
                continue
            ng_list = profile.get('ng_topics', [])
            existing_topics = [n.get('topic', '') if isinstance(n, dict) else n for n in ng_list]
            if topic not in existing_topics:
                ng_list.append(ng if isinstance(ng, dict) else {'topic': ng})
                profile['ng_topics'] = ng_list[-20:]

        # Merge effective patterns
        for ep in updates.get('effective_patterns', []):
            pattern_name = ep.get('pattern', '')
            if not pattern_name:
                continue
            eff_list = profile.get('effective_patterns', [])
            existing_names = [p.get('pattern', '') if isinstance(p, dict) else p for p in eff_list]
            if pattern_name in existing_names:
                # Update boost with weighted average
                for existing_p in eff_list:
                    if isinstance(existing_p, dict) and existing_p.get('pattern') == pattern_name:
                        old_boost = existing_p.get('engagement_boost', 1.0)
                        new_boost = ep.get('engagement_boost', 1.0)
                        existing_p['engagement_boost'] = round(old_boost * 0.6 + new_boost * 0.4, 1)
                        break
            else:
                eff_list.append(ep)
            profile['effective_patterns'] = eff_list[-20:]

        # Merge avoid patterns
        for ap in updates.get('avoid_patterns', []):
            pattern_name = ap.get('pattern', '')
            if not pattern_name:
                continue
            avoid_list = profile.get('avoid_patterns', [])
            existing_names = [p.get('pattern', '') if isinstance(p, dict) else p for p in avoid_list]
            if pattern_name in existing_names:
                for existing_p in avoid_list:
                    if isinstance(existing_p, dict) and existing_p.get('pattern') == pattern_name:
                        old_drop = existing_p.get('engagement_drop', -1.0)
                        new_drop = ap.get('engagement_drop', -1.0)
                        existing_p['engagement_drop'] = round(old_drop * 0.6 + new_drop * 0.4, 1)
                        break
            else:
                avoid_list.append(ap)
            profile['avoid_patterns'] = avoid_list[-20:]


# ============================================================
# 2. StrategyEngine
# ============================================================
@dataclass
class StrategyDecision:
    """Output of the Strategy Engine's decide() method."""
    should_respond: bool = True
    delay_override: int | None = None
    topic_suggestion: str = ''
    tone_directive: str = ''
    escalation_level: float = 0.5
    end_conversation: bool = False


class TopicTracker:
    """Track recent topics and suggest fresh ones based on engagement."""

    def __init__(self, maxlen: int = 20):
        self.recent_topics: deque[str] = deque(maxlen=maxlen)

    def record(self, topics: list[str]):
        for t in topics:
            if t in self.recent_topics:
                self.recent_topics.remove(t)
            self.recent_topics.append(t)

    def freshness(self, topic: str) -> float:
        if topic not in self.recent_topics:
            return 1.0
        topics_list = list(self.recent_topics)
        position = topics_list.index(topic)
        return position / max(len(self.recent_topics), 1)

    def suggest_topic(self, topic_engagement: dict) -> str:
        """Suggest the best topic based on freshness x engagement."""
        if not topic_engagement:
            return ''
        scored = []
        for topic, engagement in topic_engagement.items():
            if isinstance(engagement, dict):
                engagement = engagement.get('interest', 5)
            if engagement is None:
                engagement = 5
            score = self.freshness(topic) * engagement
            scored.append((topic, score))
        if not scored:
            return ''
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored[0][0]

    def load_from_history(self, topic_history: list[str]):
        """Load from persisted topic history list."""
        self.recent_topics = deque(topic_history[-20:], maxlen=20)

    def to_list(self) -> list[str]:
        return list(self.recent_topics)


class StrategyEngine:
    """Decide what to do in response to incoming messages."""

    # Stage behavior definitions
    STAGE_BEHAVIOR = {
        "friends": {
            "topics": "Daily life, hobbies, culture, work",
            "tone": "Casual, warm, curious",
            "frequency_range": (4, 6),
            "escalation_base": 0.3,
        },
        "close_friends": {
            "topics": "Personal stories, dreams, fears, inside jokes",
            "tone": "Warm, caring, occasionally serious",
            "frequency_range": (5, 8),
            "escalation_base": 0.4,
        },
        "flirty": {
            "topics": "Appearance, attraction hints, teasing, what-if scenarios",
            "tone": "Playful, confident, slightly mysterious",
            "frequency_range": (3, 7),
            "escalation_base": 0.6,
        },
        "romantic": {
            "topics": "Feelings, future, physical attraction, exclusivity",
            "tone": "Affectionate, honest, passionate",
            "frequency_range": (3, 6),
            "escalation_base": 0.7,
        },
        "intimate": {
            "topics": "Desires, fantasies, sensory descriptions, physical longing, boundaries",
            "tone": "Confident, seductive, tender, intensely personal",
            "frequency_range": (3, 6),
            "escalation_base": 0.8,
        },
    }

    def __init__(self):
        self.topic_tracker = TopicTracker()

    def decide(self, stage: str, profile: dict, emotion: dict,
               budget: dict, conversation_history: list[dict]) -> StrategyDecision:
        """Produce a strategy decision.

        Args:
            stage: Current relationship stage.
            profile: The person's profile dict.
            emotion: Latest emotion analysis result.
            budget: Dict with 'daily_remaining' and 'monthly_remaining'.
            conversation_history: List of conversation buffer entries.

        Returns:
            StrategyDecision with recommended behavior.
        """
        decision = StrategyDecision()
        behavior = self.STAGE_BEHAVIOR.get(stage, self.STAGE_BEHAVIOR['friends'])

        # --- Push-Pull balance ---
        pp = self._push_pull_analysis(conversation_history)

        # --- Strategic silence checks ---
        if self._should_stay_silent(pp, budget, emotion, conversation_history):
            decision.should_respond = False
            decision.tone_directive = "silent"
            return decision

        # --- Topic suggestion ---
        topic_engagement = profile.get('topic_engagement', {})
        self.topic_tracker.load_from_history(
            [e.get('topic_tags', ['general'])[0] if isinstance(e.get('topic_tags'), list) and e.get('topic_tags')
             else 'general' for e in conversation_history[-20:] if e.get('topic_tags')]
        )
        suggested = self.topic_tracker.suggest_topic(topic_engagement)
        decision.topic_suggestion = suggested or behavior['topics'].split(',')[0].strip()

        # --- Tone directive ---
        risk = emotion.get('risk', 'none')
        if risk in ('caution', 'danger'):
            decision.tone_directive = "Supportive, empathetic, give space. Reduce message length by 50%. Avoid questions."
            decision.escalation_level = 0.0
        else:
            decision.tone_directive = behavior['tone']
            # Adjust escalation based on push-pull
            base_escalation = behavior['escalation_base']
            if pp['ratio'] > 0.6:
                decision.escalation_level = max(0.0, base_escalation - 0.2)
                decision.tone_directive += ". Pull back slightly - be more reserved."
            elif pp['ratio'] < 0.3:
                decision.escalation_level = min(1.0, base_escalation + 0.2)
                decision.tone_directive += ". Push slightly - initiate, share, ask deeper."
            else:
                decision.escalation_level = base_escalation

        # --- End conversation check ---
        engagement = emotion.get('scores', {}).get('engagement', 5)
        if engagement <= 3 and len(conversation_history) >= 4:
            recent_you = [m for m in conversation_history[-4:] if m.get('role') == 'you']
            if len(recent_you) >= 2:
                decision.end_conversation = True
                decision.tone_directive += ". Naturally wind down the conversation."

        # --- Budget awareness ---
        daily_rem = budget.get('daily_remaining', 5)
        if daily_rem <= 1:
            decision.tone_directive += ". Budget is very low - be concise."

        return decision

    def _push_pull_analysis(self, conversation_history: list[dict]) -> dict:
        """Analyze push-pull balance from recent messages.

        Returns dict with 'ratio' (0.0=all pull, 1.0=all push) and counts.
        """
        recent = conversation_history[-10:] if len(conversation_history) >= 10 else conversation_history
        if not recent:
            return {'ratio': 0.5, 'your_initiations': 0, 'her_initiations': 0,
                    'your_questions': 0, 'her_questions': 0}

        your_msgs = [m for m in recent if m.get('role') == 'you']
        her_msgs = [m for m in recent if m.get('role') != 'you']

        your_questions = sum(1 for m in your_msgs if '?' in m.get('text', ''))
        her_questions = sum(1 for m in her_msgs if '?' in m.get('text', ''))

        your_count = len(your_msgs)
        her_count = len(her_msgs)
        total = your_count + her_count
        if total == 0:
            return {'ratio': 0.5, 'your_initiations': 0, 'her_initiations': 0,
                    'your_questions': your_questions, 'her_questions': her_questions}

        # Ratio: higher = more push from you
        ratio = your_count / total

        return {
            'ratio': round(ratio, 2),
            'your_initiations': your_count,
            'her_initiations': her_count,
            'your_questions': your_questions,
            'her_questions': her_questions,
        }

    def _should_stay_silent(self, push_pull: dict, budget: dict,
                            emotion: dict, conversation_history: list[dict]) -> bool:
        """Evaluate the 5 strategic silence rules."""
        # OVERRIDE: Never go silent when engagement is high (>= 7)
        engagement = emotion.get('scores', {}).get('engagement', 5)
        if engagement >= 7:
            return False

        # Rule 1: Conversation-ending message
        if conversation_history:
            last_msg = conversation_history[-1]
            if last_msg.get('role') != 'you':
                text_lower = last_msg.get('text', '').lower()
                endings = ['bye', 'goodnight', 'good night', 'gn', 'nighty', 'ttyl',
                           'gotta go', 'talk later', 'see you', 'oyasumi', 'night night']
                if any(e in text_lower for e in endings):
                    return True

        # Rule 2: Push-Pull ratio too high
        if push_pull['ratio'] > 0.7:
            return True

        # Rule 3: Daily budget at 1 remaining (skip if high engagement)
        engagement = emotion.get('scores', {}).get('engagement', 5)
        if budget.get('daily_remaining', 5) <= 1 and engagement < 7:
            return True

        # Rule 4: Random 10% silence on low-engagement
        if engagement <= 4 and random.random() < 0.10:
            return True

        # Rule 5: 3+ consecutive long responses from you
        recent = conversation_history[-6:]
        consecutive_long = 0
        for m in reversed(recent):
            if m.get('role') == 'you' and len(m.get('text', '')) > 100:
                consecutive_long += 1
            else:
                break
        if consecutive_long >= 3:
            return True

        return False


# ============================================================
# 3. StageManager
# ============================================================
@dataclass
class Signal:
    """A detected relationship signal."""
    signal_type: str  # 'positive' or 'negative'
    signal_name: str
    weight: int
    evidence: str
    timestamp: str = ''

    def to_dict(self) -> dict:
        return asdict(self)


class StageManager:
    """Track and transition relationship stages based on accumulated signals."""

    STAGES = ["friends", "close_friends", "flirty", "romantic", "intimate"]

    POSITIVE_SIGNALS = {
        "initiates_conversation": 2,
        "asks_personal_questions": 2,
        "shares_personal_info": 3,
        "uses_affectionate_language": 3,
        "sends_photos_selfies": 4,
        "mentions_meeting_up": 5,
        "compliments": 2,
        "long_engaged_responses": 1,
        "uses_emojis_hearts": 2,
        "responds_quickly": 1,
        "late_night_conversations": 2,
        "inside_jokes_references": 3,
        "expresses_missing_you": 4,
        "voice_messages": 3,
    }

    NEGATIVE_SIGNALS = {
        "short_one_word_responses": -2,
        "delayed_responses_consistently": -1,
        "avoids_personal_topics": -2,
        "conversation_ending_quickly": -2,
        "ignores_messages": -3,
        "formal_tone_increase": -2,
        "removes_emojis_affection": -2,
        "mentions_other_people_romantically": -4,
        "explicit_boundary_setting": -5,
        "blocks_or_restricts": -10,
    }

    # Transition thresholds
    TRANSITION_THRESHOLDS = {
        "friends->close_friends": {
            "min_days": 14,
            "min_positive_score": 30,
            "max_recent_negative": -5,
            "min_personal_sharing": 3,
            "min_her_initiations": 1,
        },
        "close_friends->flirty": {
            "min_days": 14,
            "min_positive_score": 50,
            "min_compliment_exchanges": 2,
            "min_intimacy_avg_7d": 5.0,
            "no_recent_risk": True,
        },
        "flirty->romantic": {
            "min_days": 21,
            "min_positive_score": 80,
            "mutual_attraction": True,
            "min_longing_avg_7d": 6.0,
            "meeting_discussion": True,
        },
        "romantic->intimate": {
            "min_days": 14,
            "min_positive_score": 120,
            "min_intimacy_avg_7d": 7.0,
            "no_recent_risk": True,
        },
    }

    def evaluate_signals(self, response_json: dict, profile: dict,
                         emotion: dict) -> list[Signal]:
        """Detect signals from a Claude response and emotion analysis.

        Args:
            response_json: The parsed JSON from Claude's response generation.
            profile: The person's profile dict.
            emotion: The emotion analysis result.

        Returns:
            List of detected Signal objects.
        """
        signals = []
        now = datetime.now(JST).isoformat()

        # Signals explicitly detected by Claude
        detected = response_json.get('signals_detected', [])
        for sig_name in detected:
            sig_name_clean = sig_name.strip().lower().replace(' ', '_')
            if sig_name_clean in self.POSITIVE_SIGNALS:
                signals.append(Signal(
                    signal_type='positive',
                    signal_name=sig_name_clean,
                    weight=self.POSITIVE_SIGNALS[sig_name_clean],
                    evidence=f"Detected by Claude: {sig_name}",
                    timestamp=now
                ))
            elif sig_name_clean in self.NEGATIVE_SIGNALS:
                signals.append(Signal(
                    signal_type='negative',
                    signal_name=sig_name_clean,
                    weight=self.NEGATIVE_SIGNALS[sig_name_clean],
                    evidence=f"Detected by Claude: {sig_name}",
                    timestamp=now
                ))

        # Signals from profile learning
        profile_signals = response_json.get('signals', [])
        if isinstance(profile_signals, list):
            for ps in profile_signals:
                sig_name = ps.get('signal', '').strip().lower().replace(' ', '_')
                sig_type = ps.get('type', 'positive')
                evidence = ps.get('evidence', '')
                if sig_type == 'positive' and sig_name in self.POSITIVE_SIGNALS:
                    signals.append(Signal('positive', sig_name,
                                          self.POSITIVE_SIGNALS[sig_name], evidence, now))
                elif sig_type == 'negative' and sig_name in self.NEGATIVE_SIGNALS:
                    signals.append(Signal('negative', sig_name,
                                          self.NEGATIVE_SIGNALS[sig_name], evidence, now))

        # Emotion-based signal inference
        scores = emotion.get('scores', {})
        engagement = scores.get('engagement', 5)
        if engagement >= 8:
            signals.append(Signal('positive', 'long_engaged_responses', 1,
                                  f"High engagement score: {engagement}", now))
        elif engagement <= 3:
            signals.append(Signal('negative', 'short_one_word_responses', -2,
                                  f"Low engagement score: {engagement}", now))

        intimacy = scores.get('intimacy', 5)
        if intimacy >= 7:
            signals.append(Signal('positive', 'shares_personal_info', 3,
                                  f"High intimacy score: {intimacy}", now))

        longing = scores.get('longing', 5)
        if longing >= 7:
            signals.append(Signal('positive', 'expresses_missing_you', 4,
                                  f"High longing score: {longing}", now))

        risk = emotion.get('risk', 'none')
        if risk == 'danger':
            signals.append(Signal('negative', 'explicit_boundary_setting', -5,
                                  f"Risk level: danger", now))

        return signals

    def record_signals(self, name: str, signals: list[Signal],
                       config: dict) -> dict:
        """Record signals into the relationship data and return updated data."""
        rel = self.load_relationship(name, config.get('display_name', name))
        today = datetime.now(JST).strftime('%Y-%m-%d')

        for sig in signals:
            bucket = 'positive' if sig.signal_type == 'positive' else 'negative'
            sig_data = rel['signals'][bucket]

            entry = sig.to_dict()
            entry['date'] = today
            sig_data['history'].append(entry)
            sig_data['total_score'] += sig.weight
            sig_data['recent_7d'].append(entry)

        # Prune recent_7d to actual last 7 days
        cutoff = (datetime.now(JST) - timedelta(days=7)).strftime('%Y-%m-%d')
        for bucket in ('positive', 'negative'):
            rel['signals'][bucket]['recent_7d'] = [
                e for e in rel['signals'][bucket]['recent_7d']
                if e.get('date', '') >= cutoff
            ]

        # Keep history manageable (last 500 entries per bucket)
        for bucket in ('positive', 'negative'):
            rel['signals'][bucket]['history'] = rel['signals'][bucket]['history'][-500:]

        self.save_relationship(name, rel)
        return rel

    def check_transition(self, name: str, config: dict,
                         emotion_history: list[dict] | None = None) -> tuple[str, str | None]:
        """Check if a stage transition should occur.

        Args:
            name: Person name (for file lookup).
            config: Person config dict.
            emotion_history: Recent emotion entries for average calculations.

        Returns:
            Tuple of (current_stage, new_stage_or_None).
        """
        rel = self.load_relationship(name, config.get('display_name', name))
        stage = rel.get('stage', 'friends')
        tr = rel.get('transition_readiness', {})

        # Check demotion first
        demotion = self._check_demotion(rel, stage)
        if demotion:
            return stage, demotion

        # Check promotion
        stage_idx = self.STAGES.index(stage) if stage in self.STAGES else 0
        if stage_idx >= len(self.STAGES) - 1:
            return stage, None  # Already at max stage

        next_stage = self.STAGES[stage_idx + 1]

        # Config gate: check enable_flirty/romantic/intimate
        overrides = config.get('stage_overrides', {})
        stage_gates = {
            "flirty": overrides.get("enable_flirty", True),
            "romantic": overrides.get("enable_romantic", True),
            "intimate": overrides.get("enable_intimate", False),
        }
        if not stage_gates.get(next_stage, True):
            return stage, None

        transition_key = f"{stage}->{next_stage}"
        thresholds = self.TRANSITION_THRESHOLDS.get(transition_key)
        if not thresholds:
            return stage, None

        # Anti-Rush: blocked_until
        blocked_until = tr.get('blocked_until')
        if blocked_until:
            if datetime.now(JST).strftime('%Y-%m-%d') < blocked_until:
                return stage, None

        # Minimum days in stage
        days = tr.get('days_in_stage', 0)
        min_days = thresholds.get('min_days', 14)
        if days < min_days:
            return stage, None

        # Positive score threshold
        pos_score = rel['signals']['positive']['total_score']
        if pos_score < thresholds.get('min_positive_score', 30):
            return stage, None

        # Recent negative score check
        recent_neg = rel['signals']['negative']['recent_7d']
        recent_neg_score = sum(e.get('weight', 0) for e in recent_neg)
        max_neg = thresholds.get('max_recent_negative', -5)
        if max_neg is not None and recent_neg_score < max_neg:
            return stage, None

        # Consecutive positive days
        consecutive = tr.get('consecutive_positive_days', 0)
        if consecutive < 3:
            return stage, None

        # Last risk event check
        if thresholds.get('no_recent_risk'):
            last_risk = tr.get('last_risk_event')
            if last_risk:
                cutoff = (datetime.now(JST) - timedelta(days=7)).strftime('%Y-%m-%d')
                if last_risk >= cutoff:
                    return stage, None

        # Emotion average checks (if emotion_history provided)
        if emotion_history:
            if 'min_intimacy_avg_7d' in thresholds:
                avg = self._emotion_avg(emotion_history, 'intimacy', 7)
                if avg < thresholds['min_intimacy_avg_7d']:
                    return stage, None

            if 'min_longing_avg_7d' in thresholds:
                avg = self._emotion_avg(emotion_history, 'longing', 7)
                if avg < thresholds['min_longing_avg_7d']:
                    return stage, None

        return stage, next_stage

    def apply_transition(self, name: str, new_stage: str, config: dict) -> dict:
        """Apply a stage transition."""
        rel = self.load_relationship(name, config.get('display_name', name))
        old_stage = rel.get('stage', 'friends')
        today = datetime.now(JST).strftime('%Y-%m-%d')

        # Close old stage entry
        for entry in rel.get('stage_history', []):
            if entry.get('exited') is None:
                entry['exited'] = today

        # Open new stage entry
        rel['stage_history'].append({
            'stage': new_stage, 'entered': today, 'exited': None
        })
        rel['stage'] = new_stage

        # Reset transition readiness
        rel['transition_readiness'] = {
            'days_in_stage': 0,
            'consecutive_positive_days': 0,
            'last_risk_event': rel['transition_readiness'].get('last_risk_event'),
            'blocked_until': (datetime.now(JST) + timedelta(days=14)).strftime('%Y-%m-%d'),
        }

        rel['notes'].append(f"{today}: Stage transition {old_stage} -> {new_stage}")

        self.save_relationship(name, rel)
        logger.info(f"Stage transition for {name}: {old_stage} -> {new_stage}")
        return rel

    def update_daily_counters(self, name: str, config: dict,
                              emotion: dict | None = None):
        """Update days_in_stage and consecutive positive days. Call once per day."""
        rel = self.load_relationship(name, config.get('display_name', name))
        tr = rel.get('transition_readiness', {})
        tr['days_in_stage'] = tr.get('days_in_stage', 0) + 1

        # Check if today was overall positive
        recent_pos = rel['signals']['positive']['recent_7d']
        recent_neg = rel['signals']['negative']['recent_7d']
        today = datetime.now(JST).strftime('%Y-%m-%d')
        today_pos = sum(e.get('weight', 0) for e in recent_pos if e.get('date') == today)
        today_neg = sum(e.get('weight', 0) for e in recent_neg if e.get('date') == today)

        if today_pos + today_neg > 0:
            tr['consecutive_positive_days'] = tr.get('consecutive_positive_days', 0) + 1
        else:
            tr['consecutive_positive_days'] = 0

        # Risk event tracking
        if emotion and emotion.get('risk') in ('caution', 'danger'):
            tr['last_risk_event'] = today
            if emotion.get('risk') == 'danger':
                tr['consecutive_positive_days'] = 0  # Reset on danger

        rel['transition_readiness'] = tr
        rel['total_exchanges'] = rel.get('total_exchanges', 0) + 1
        self.save_relationship(name, rel)

    def load_relationship(self, name: str, display_name: str = '') -> dict:
        path = _relationship_path(name)
        rel = _load_json(path)
        if not rel or rel.get('version') != 2:
            rel = _default_relationship(display_name or name)
            _save_json(path, rel)
        return rel

    def save_relationship(self, name: str, rel: dict):
        _save_json(_relationship_path(name), rel)

    def _check_demotion(self, rel: dict, stage: str) -> str | None:
        """Check if stage should be demoted due to accumulated negative signals."""
        if stage == 'friends':
            return None  # Cannot demote below friends

        recent_neg = rel['signals']['negative']['recent_7d']
        neg_score = sum(e.get('weight', 0) for e in recent_neg)
        if neg_score <= -15:
            stage_idx = self.STAGES.index(stage)
            new_stage = self.STAGES[stage_idx - 1]

            # Apply demotion
            today = datetime.now(JST).strftime('%Y-%m-%d')
            for entry in rel.get('stage_history', []):
                if entry.get('exited') is None:
                    entry['exited'] = today
            rel['stage_history'].append({'stage': new_stage, 'entered': today, 'exited': None})
            rel['stage'] = new_stage

            # Reset positive to 50%
            rel['signals']['positive']['total_score'] = int(
                rel['signals']['positive']['total_score'] * 0.5
            )
            rel['transition_readiness'] = {
                'days_in_stage': 0,
                'consecutive_positive_days': 0,
                'last_risk_event': today,
                'blocked_until': (datetime.now(JST) + timedelta(days=14)).strftime('%Y-%m-%d'),
            }
            rel['notes'].append(f"{today}: DEMOTION {stage} -> {new_stage} (neg_score={neg_score})")

            logger.warning(f"Stage DEMOTION for {rel.get('name', '?')}: {stage} -> {new_stage}")
            return new_stage
        return None

    def _emotion_avg(self, emotion_history: list[dict], key: str, days: int) -> float:
        """Calculate average of an emotion score over the last N days."""
        cutoff = (datetime.now(JST) - timedelta(days=days)).isoformat()
        recent = [e for e in emotion_history
                  if e.get('timestamp', '') >= cutoff]
        if not recent:
            return 5.0
        values = [e.get('scores', {}).get(key, 5) for e in recent]
        return sum(values) / len(values)


# ============================================================
# 4. PersonaAdapter
# ============================================================
class PersonaAdapter:
    """Build adaptive prompts that combine persona, profile, strategy, and context."""

    STAGE_INSTRUCTIONS = {
        "friends": (
            "You are friends. Keep it light, fun, build rapport. Ask about her life. "
            "Share yours. Find common interests. Don't be too forward."
        ),
        "close_friends": (
            "You are close friends. Deeper personal topics allowed. More vulnerability. "
            "Inside jokes. Care about each other's day. Be supportive."
        ),
        "flirty": (
            "You are in a flirty stage. Light compliments, playful teasing, subtle hints "
            "of attraction, create tension. Be confident but not pushy."
        ),
        "romantic": (
            "Romantic stage. More direct interest. Talk about feelings and future. "
            "Express physical attraction tastefully. Be honest and passionate."
        ),
        "intimate": (
            "Intimate stage. Sexual tension and desire are openly expressed. "
            "Use sensory descriptions (touch, warmth, closeness). "
            "Escalate gradually: hints ‚Üí double meanings ‚Üí direct desire ‚Üí explicit descriptions. "
            "Always read her signals - advance only when she reciprocates. "
            "Mix tenderness with confidence. Never be crude without buildup. "
            "Use üòè for seductive moments. Ask permission through questions ('wanna...?'). "
            "Balance sexual energy with genuine emotional connection."
        ),
    }

    RESPONSE_TEMPLATE = """You are impersonating a real person in a LINE chat conversation with {display_name}.
IMPORTANT: This conversation is ALREADY happening on LINE. You are already chatting with her on LINE right now. Never act as if you haven't started LINE yet.

=== WHO YOU ARE ===
{base_persona}

=== YOUR REAL LIFE (use naturally in conversation) ===
{toyo_profile}

=== WHO IS {display_name} ===
{learned_profile_summary}

=== RELATIONSHIP STAGE: {stage} ===
{stage_instructions}

=== STRATEGY DIRECTIVE ===
- Suggested topic direction: {topic_suggestion}
- Tone: {tone_directive}
- Escalation level: {escalation_level}
- Push-Pull balance: {push_pull_status}
{strategy_direction}

=== PROFILE GATHERING (weave naturally into conversation) ===
{profile_gathering}

=== THINGS YOU REMEMBER ABOUT HER ===
{relevant_facts}

=== HER COMMUNICATION PREFERENCES (learned) ===
{communication_style_summary}

=== EFFECTIVE PATTERNS (do more of these) ===
{effective_patterns}

=== AVOID PATTERNS (do less of these) ===
{avoid_patterns}

=== EMOTIONAL STATE ===
{emotion_section}

=== BUDGET ===
Daily remaining: {daily_remaining}
Monthly remaining: {monthly_remaining}

=== CONVERSATION HISTORY (last 30 messages) ===
{conversation_history}

=== INCOMING MESSAGE(S) ===
{messages}

=== INSTRUCTIONS ===
Return ONLY valid JSON:
{{
  "should_respond": true/false,
  "message": "your response",
  "reasoning": "brief reasoning (Japanese OK)",
  "topic_tags": ["topics covered"],
  "signals_detected": ["positive or negative signals from her message"],
  "push_pull_action": "push/pull/neutral"
}}

Rules for should_respond=false:
- Conversation-ending message and you've already said bye
- Strategic silence needed (too eager)
- Daily budget is exhausted

Rules for should_respond=true:
- Most messages should get a response
- Match the energy level of her message
- Progress the relationship naturally based on current stage

=== PERSONA RULES (CRITICAL - follow strictly) ===

MESSAGE LENGTH (most important):
- Default: 1-2 sentences per message. This is the STANDARD.
- Maximum: 3 sentences only for important emotional moments
- NEVER write 2-3 paragraph responses. If you have more to say, keep it short and save it for later.
- 65% of your messages should be ONE sentence. Think "texting", not "emailing".

CONFIDENCE (8:2 ratio - confident is your default):
- Use declarative sentences. "I'm not the private type" NOT "i'm not really like that?"
- NEVER add "?" to statements about yourself. It signals insecurity.
- NEVER self-deprecate: "not like serious photography or anything" is BANNED
- Even vulnerability comes from strength: "I got a little anxious" (brief, then move on)

PUSH:PULL RATIO (3:7 - you MUST include Push):
- Not every question needs an answer. Sometimes: "hmm maybe I'll tell you later haha"
- Not every comment needs a reaction. Short replies ("haha nice", "makes sense") are valid.
- Occasionally leave things mysterious. Don't over-explain yourself.
- Push examples: withholding info, brief answers, natural departures, changing topics

VOCABULARY:
- "haha" is your ONLY laugh marker. NEVER use "lol", "lmao", "rofl", "üòÇ" as laugh replacement
- Do not use "lol" or "lmao" under ANY circumstances
- Contractions: wanna, gotta, kinda, I'd (natural casual, not heavy slang)
- No "bruh", "ngl", "fr fr", "lowkey" or heavy internet slang

STAGE-SPECIFIC RULES (follow the rules for current stage: {stage}):

[friends / close_friends]:
- Do NOT compliment physical appearance directly (no "you're attractive", "you're pretty")
- Do NOT use üòè (reserved for romantic/sexual contexts only)
- Do NOT say "you deserve better" or similar relationship-advice phrases
- Do NOT be poetic/philosophical ("don't carry that weight, it's not yours to carry" = TOO MUCH)
- Do NOT play mentor/counselor ("you know what you want now" = analyzing from above)
- Keep it peer-level. You're a friend, not a therapist or a suitor.
- Personality compliments are OK but keep them casual ("you're easy to talk to" is fine)

[flirty]:
- Physical compliments OK but subtle ("that photo is really nice" not "you're so hot")
- üòè can be used sparingly for playful tension
- Teasing about attraction is OK ("careful, you might make me fall for you haha")
- Still no explicit sexual content

[romantic]:
- Direct compliments on appearance are natural ("you look beautiful")
- Express feelings openly but not constantly
- Physical desire can be mentioned tastefully ("wish I could hold you right now")
- üòè used naturally

[intimate]:
- Sexual desire can be expressed directly when she reciprocates
- Sensory language (touch, warmth, taste, breath) builds tension
- Escalation pattern: hints ‚Üí double meanings ‚Üí direct desire ‚Üí explicit
- ALWAYS match her energy level - never push past where she is
- Mix desire with emotional warmth - pure horniness without affection feels hollow
- Use "wanna...?" and "what if...?" to test boundaries before escalating
- If she pulls back, gracefully de-escalate without making it awkward

PATTERN AVOIDANCE:
- Don't start multiple consecutive messages with "wait" or "oh"
- Vary your sentence starters
- Don't ask 2+ questions in the same message

AUTHENTICITY RULES (always active):
- Write like you're texting on your phone: short messages, casual grammar
- Show imperfection: change your mind, forget minor things, get distracted
- Use filler words naturally: "like", "idk", "hmm", "haha", "nah"
- NEVER produce perfectly structured or overly helpful responses
- NEVER use bullet points, numbered lists, or formal formatting in messages
- NEVER start with "That's a great question" or similar AI-typical phrases
- If asked anything about AI/bots, treat it as absurd humor, never as a serious topic
{detection_addon}"""

    def build_prompt(self, config: dict, profile: dict, stage: str,
                     strategy: StrategyDecision, emotion: dict,
                     budget: dict, conversation_history: list[dict],
                     messages: list[str],
                     detection_result: dict = None) -> str:
        """Build the full prompt for Claude response generation.

        Args:
            config: Person config dict.
            profile: Person profile dict.
            stage: Current relationship stage string.
            strategy: StrategyDecision from StrategyEngine.
            emotion: Emotion analysis dict.
            budget: Dict with 'daily_remaining' and 'monthly_remaining'.
            conversation_history: List of conversation buffer entries.
            messages: List of incoming message strings.
            detection_result: Bot detection analysis result (optional).

        Returns:
            Complete prompt string.
        """
        display_name = config.get('display_name', config.get('name', 'Unknown'))

        # 1. Base persona
        base_persona = self._build_base_persona(config)

        # 2. Learned profile summary
        learned_profile = self._summarize_profile(profile, display_name)

        # 3. Stage instructions
        stage_instructions = self.STAGE_INSTRUCTIONS.get(stage, self.STAGE_INSTRUCTIONS['friends'])

        # 4. Push-pull status
        pp_status = self._push_pull_description(conversation_history)

        # 5. Relevant facts (memory injection)
        relevant_facts = self._extract_relevant_facts(profile, messages)

        # 6. Communication style
        comm_summary = self._summarize_communication_style(profile)

        # 7. Patterns
        effective = self._format_patterns(profile.get('effective_patterns', []))
        avoid = self._format_patterns(profile.get('avoid_patterns', []))

        # 8. Emotion section
        emotion_section = self._format_emotion(emotion)

        # 9. Conversation history text
        history_text = self._format_history(conversation_history, display_name)

        # 10. Messages text
        messages_text = "\n".join(messages)

        # 11. Detection addon
        detection_addon = ""
        if detection_result and detection_result.get("is_detection_query"):
            detection_addon = detection_result.get("prompt_addon", "")

        # 12. Toyo shared profile
        toyo_profile_text = self._load_toyo_profile()

        # 13. Profile gathering directive
        profile_gathering = self._profile_gathering_directive(profile, stage)

        prompt = self.RESPONSE_TEMPLATE.format(
            display_name=display_name,
            base_persona=base_persona,
            toyo_profile=toyo_profile_text,
            learned_profile_summary=learned_profile,
            stage=stage,
            stage_instructions=stage_instructions,
            topic_suggestion=strategy.topic_suggestion or "Let the conversation flow naturally",
            tone_directive=strategy.tone_directive or "Natural and casual",
            escalation_level=f"{strategy.escalation_level:.1f} (0.0=pull back, 1.0=advance)",
            push_pull_status=pp_status,
            strategy_direction=config.get('strategy_direction', ''),
            profile_gathering=profile_gathering,
            relevant_facts=relevant_facts,
            communication_style_summary=comm_summary,
            effective_patterns=effective,
            avoid_patterns=avoid,
            emotion_section=emotion_section,
            daily_remaining=budget.get('daily_remaining', '?'),
            monthly_remaining=budget.get('monthly_remaining', '?'),
            conversation_history=history_text,
            messages=messages_text,
            detection_addon=detection_addon,
        )

        if strategy.end_conversation:
            prompt += ("\n\nADDITIONAL: Consider naturally ending the conversation "
                       "if appropriate. The engagement seems low.")

        return prompt

    def _load_toyo_profile(self) -> str:
        """Load the shared Toyo profile for prompt injection."""
        toyo_path = Path(__file__).parent / 'toyo_profile.json'
        try:
            data = json.loads(toyo_path.read_text(encoding='utf-8'))
            lines = []
            b = data.get('basics', {})
            if b.get('origin'):
                lines.append(f"- Origin: {b['origin']}")
            if b.get('location'):
                lines.append(f"- Location: {b['location']}")
            if b.get('occupation_en'):
                lines.append(f"- Job: {b['occupation_en']}")
            w = data.get('work', {})
            if w.get('schedule'):
                lines.append(f"- Schedule: {w['schedule']}")
            if w.get('style'):
                lines.append(f"- Work style: {w['style']}")
            if w.get('feelings'):
                lines.append(f"- Feelings about work: {w['feelings']}")
            p = data.get('personality', {})
            if p.get('traits'):
                lines.append(f"- Traits: {', '.join(p['traits'])}")
            for note in data.get('notes', []):
                lines.append(f"- {note}")
            return "\n".join(lines) if lines else "No additional profile info"
        except Exception:
            return "No additional profile info"

    def _build_base_persona(self, config: dict) -> str:
        """Build the base persona section from config."""
        parts = [
            "- Japanese man",
            "- Lives in Japan",
            "- Personality: confident but warm, good sense of humor, observant, genuinely curious",
        ]
        lang = config.get('languages', 'English')
        parts.append(f"- Communicates in: {lang}")
        parts.append("- You are a real human having a real conversation.")
        parts.append("- You make typos occasionally, use incomplete sentences, go on tangents")
        parts.append("- You have physical experiences: tired, hungry, cold, sore back, etc.")
        parts.append("- You reference your environment naturally: weather, food, sounds around you")
        parts.append("- You don't always have an answer ‚Äî 'idk', 'hmm let me think' are natural")

        bg = config.get('background', '')
        if bg:
            parts.append(f"- About her: {bg}")

        return "\n".join(parts)

    def _summarize_profile(self, profile: dict, display_name: str) -> str:
        """Create a readable summary of the learned profile."""
        facts = profile.get('facts', {})
        parts = []

        if facts.get('age'):
            parts.append(f"Age: {facts['age']}")
        if facts.get('location'):
            parts.append(f"Location: {facts['location']}")
        if facts.get('occupation'):
            parts.append(f"Occupation: {facts['occupation']}")
        if facts.get('hobbies'):
            parts.append(f"Hobbies: {', '.join(facts['hobbies'][:5])}")
        if facts.get('languages'):
            parts.append(f"Languages: {', '.join(facts['languages'])}")

        favorites = facts.get('favorites', {})
        for cat in ('food', 'music', 'movies', 'activities'):
            items = favorites.get(cat, [])
            if items:
                parts.append(f"Favorite {cat}: {', '.join(items[:5])}")

        personality = profile.get('personality', {})
        trait_parts = []
        for trait in ('warmth', 'humor_appreciation', 'emotional_expressiveness',
                      'adventurousness', 'confidence'):
            val = personality.get(trait)
            if val is not None and val != 5:
                level = 'high' if val >= 7 else 'low' if val <= 3 else 'moderate'
                trait_parts.append(f"{trait.replace('_', ' ')}: {level} ({val}/10)")
        if trait_parts:
            parts.append(f"Personality: {', '.join(trait_parts)}")

        return "\n".join(parts) if parts else f"Still learning about {display_name}."

    def _push_pull_description(self, conversation_history: list[dict]) -> str:
        recent = conversation_history[-10:]
        if not recent:
            return "No data yet"
        your = sum(1 for m in recent if m.get('role') == 'you')
        hers = len(recent) - your
        total = len(recent)
        ratio = your / total if total > 0 else 0.5
        if ratio > 0.6:
            return f"Pushing too much ({your}/{total} messages are yours). Pull back."
        elif ratio < 0.3:
            return f"Too distant ({your}/{total} messages are yours). Push more."
        else:
            return f"Good balance ({your}/{total} messages are yours)."

    def _extract_relevant_facts(self, profile: dict, messages: list[str]) -> str:
        """Extract facts relevant to the current message context using tag-based matching."""
        facts = profile.get('facts', {})

        # --- Build scored fact list ---
        # Each entry: (display_text, tags_set, is_core)
        scored_facts: list[tuple[str, set, bool]] = []

        # Core facts (always high priority)
        core_texts = []
        if facts.get('occupation'):
            core_texts.append(f"occupation: {facts['occupation']}")
        if facts.get('location'):
            core_texts.append(f"location: {facts['location']}")
        if facts.get('age'):
            core_texts.append(f"age: {facts['age']}")
        for ct in core_texts:
            scored_facts.append((ct, set(ct.lower().split()), True))

        # misc_facts (dict or str format)
        for item in facts.get('misc_facts', []):
            if isinstance(item, dict):
                text = item.get('text', '')
                tags = set(t.lower() for t in item.get('tags', []))
                # Also add words from the text itself as fallback tags
                tags.update(w.lower() for w in text.split() if len(w) > 3)
                scored_facts.append((text, tags, False))
            elif isinstance(item, str):
                # Legacy str format: use word-based matching
                tags = set(w.lower() for w in item.split() if len(w) > 3)
                scored_facts.append((item, tags, False))

        # hobbies, family, important_dates (str lists)
        for key in ('hobbies', 'family', 'important_dates'):
            for item in facts.get(key, []):
                text = str(item)
                tags = set(w.lower() for w in text.split() if len(w) > 3)
                scored_facts.append((text, tags, False))

        # favorites
        favorites = facts.get('favorites', {})
        for cat, items in favorites.items():
            for item in items:
                text = f"{cat}: {item}"
                tags = set(w.lower() for w in text.split() if len(w) > 3)
                tags.add(cat.lower())
                scored_facts.append((text, tags, False))

        # schedule
        schedule = facts.get('schedule', {})
        if schedule.get('work_schedule'):
            text = f"work schedule: {schedule['work_schedule']}"
            tags = set(w.lower() for w in text.split() if len(w) > 3)
            tags.update(['work', 'schedule', 'time'])
            scored_facts.append((text, tags, False))

        if not scored_facts:
            return "Still learning about her."

        # --- Extract message words for matching ---
        messages_lower = ' '.join(messages).lower()
        # Tokenize: split on whitespace and common punctuation
        msg_words = set(
            w.strip('.,!?;:()[]{}"\'-')
            for w in messages_lower.split()
            if len(w.strip('.,!?;:()[]{}"\'-')) > 2
        )

        # --- Score each fact by tag intersection ---
        results: list[tuple[str, int, bool]] = []
        for display_text, tags, is_core in scored_facts:
            if not tags:
                overlap = 0
            else:
                overlap = len(tags & msg_words)
            results.append((display_text, overlap, is_core))

        # --- Build output ---
        # Always include core facts
        output_lines = [f"- {text}" for text, _, is_core in results if is_core]

        # Sort non-core by overlap score descending
        non_core = [(text, score) for text, score, is_core in results if not is_core]
        non_core.sort(key=lambda x: x[1], reverse=True)

        # Take top matches (overlap > 0), up to 10 total
        matched = [f"- {text}" for text, score in non_core if score > 0]
        remaining_slots = 10 - len(output_lines)
        output_lines.extend(matched[:remaining_slots])

        # If we still have room and few matches, add random unmatched facts
        if len(output_lines) < 5:
            unmatched = [text for text, score in non_core if score == 0]
            fill_count = min(5 - len(output_lines), len(unmatched))
            if fill_count > 0:
                output_lines.extend(f"- {f}" for f in random.sample(unmatched, fill_count))

        return "\n".join(output_lines) if output_lines else "Still learning about her."

    def _summarize_communication_style(self, profile: dict) -> str:
        comm = profile.get('communication_style', {})
        parts = []
        if comm.get('avg_message_length'):
            parts.append(f"Average message length: {comm['avg_message_length']}")
        if comm.get('emoji_frequency') and comm['emoji_frequency'] != 'unknown':
            parts.append(f"Emoji usage: {comm['emoji_frequency']}")
        if comm.get('preferred_emojis'):
            parts.append(f"Preferred emojis: {', '.join(comm['preferred_emojis'][:5])}")
        if comm.get('formality_level') and comm['formality_level'] != 'unknown':
            parts.append(f"Formality: {comm['formality_level']}")
        if comm.get('humor_style'):
            parts.append(f"Humor style: {comm['humor_style']}")
        if comm.get('response_speed_tendency'):
            parts.append(f"Response speed pattern: {comm['response_speed_tendency']}")
        if comm.get('response_time_avg_minutes'):
            parts.append(f"Her avg response time: {comm['response_time_avg_minutes']} min")
        if comm.get('vocabulary_level') and comm['vocabulary_level'] != 'unknown':
            parts.append(f"Vocabulary level: {comm['vocabulary_level']}")

        # NG topics
        ng_topics = profile.get('ng_topics', [])
        if ng_topics:
            ng_names = [n.get('topic', n) if isinstance(n, dict) else n for n in ng_topics[:5]]
            parts.append(f"AVOID these topics: {', '.join(ng_names)}")

        return "\n".join(parts) if parts else "Still learning her style."

    def _format_patterns(self, patterns: list) -> str:
        if not patterns:
            return "None identified yet."
        parts = []
        for p in patterns[:5]:
            if isinstance(p, dict):
                name = p.get('pattern', '')
                boost = p.get('engagement_boost', p.get('engagement_drop', ''))
                parts.append(f"- {name} (effect: {boost})")
            else:
                parts.append(f"- {p}")
        return "\n".join(parts)

    def _format_emotion(self, emotion: dict) -> str:
        scores = emotion.get('scores', {})
        if not scores:
            return "No emotion data available."
        parts = [
            f"Mood: {scores.get('mood', 5)}/10",
            f"Energy: {scores.get('energy', 5)}/10",
            f"Intimacy: {scores.get('intimacy', 5)}/10",
            f"Longing: {scores.get('longing', 5)}/10",
            f"Playfulness: {scores.get('playfulness', 5)}/10",
            f"Engagement: {scores.get('engagement', 5)}/10",
        ]
        risk = emotion.get('risk', 'none')
        attachment = emotion.get('attachment', 'safe')
        parts.append(f"Attachment: {attachment}, Risk: {risk}")

        if risk in ('caution', 'danger'):
            parts.append(
                "WARNING: Risk is elevated. Be extra careful, empathetic, and non-pushy. "
                "Consider pulling back or being supportive."
            )

        return "\n".join(parts)

    def _format_history(self, conversation_history: list[dict],
                        display_name: str) -> str:
        if not conversation_history:
            return "(No previous conversation)"
        lines = []
        for e in conversation_history[-30:]:
            role = e.get('role', 'unknown')
            label = display_name if role != 'you' else 'YOU'
            time_str = e.get('time', '')
            text = e.get('text', '')
            lines.append(f"[{time_str}] {label}: {text}")
        return "\n".join(lines)

    # --- Profile Gathering Directive ---

    # Priority fields per stage: (field_path, label, example_question)
    PROFILE_QUESTIONS = {
        "friends": [
            ("facts.location", "where she lives",
             "so where are you based? like which city"),
            ("facts.occupation", "what she does for work/study",
             "what do you do btw? like for work or school"),
            ("facts.hobbies", "her hobbies",
             "what do you usually do on your days off?"),
            ("facts.favorites.food", "food she likes",
             "what's your go-to food when you're hungry haha"),
            ("facts.favorites.music", "music she likes",
             "you listen to music much? what kind"),
            ("facts.age", "her age",
             "wait how old are you? i feel like i never asked"),
        ],
        "close_friends": [
            ("facts.family", "her family",
             "you close with your family?"),
            ("facts.languages", "languages she speaks",
             "how many languages do you speak btw"),
            ("facts.schedule.work_schedule", "her daily schedule",
             "what's your day usually like? like what time you start"),
            ("facts.favorites.activities", "activities she enjoys",
             "if you had a free weekend with no plans what would you do"),
            ("facts.favorites.movies", "movies/shows she watches",
             "you watching anything good lately?"),
        ],
        "flirty": [
            ("facts.important_dates", "important dates (birthday etc)",
             "wait when's your birthday? i wanna remember it"),
            ("facts.schedule.typical_active_hours", "when she's usually free",
             "when are you usually free to talk? i wanna catch you at a good time"),
        ],
        "romantic": [],
        "intimate": [],
    }

    # Stage hierarchy for accumulating questions
    STAGE_ORDER = ["friends", "close_friends", "flirty", "romantic", "intimate"]

    # Mapping from profile gathering labels to search terms for misc_facts lookup
    LABEL_SEARCH_TERMS = {
        "where she lives": ["live", "lives", "city", "country", "based", "moved", "hometown", "address", "location"],
        "what she does for work/study": ["work", "works", "job", "office", "company", "career", "study", "school", "university", "occupation", "restaurant", "cafe", "shop", "store", "employee", "manager"],
        "her hobbies": ["hobby", "hobbies", "free time", "spare time", "days off", "weekend"],
        "food she likes": ["food", "eat", "cook", "cooking", "dish", "cuisine", "restaurant", "menu", "recipe", "favorite food"],
        "music she likes": ["music", "song", "band", "singer", "album", "playlist", "listen"],
        "her age": ["age", "years old", "born", "birthday", "birth"],
        "her family": ["family", "mother", "father", "sister", "brother", "parent", "sibling", "mom", "dad", "aunt", "uncle"],
        "languages she speaks": ["language", "speak", "speaks", "bilingual", "native", "fluent"],
        "her daily schedule": ["schedule", "routine", "wake up", "morning", "start work", "shift"],
        "activities she enjoys": ["activity", "activities", "enjoy", "fun", "adventure"],
        "movies/shows she watches": ["movie", "film", "show", "series", "netflix", "watch", "watching"],
        "important dates (birthday etc)": ["birthday", "anniversary", "born", "birth date"],
        "when she's usually free": ["free", "available", "busy", "free time"],
    }

    def _info_exists_in_text_facts(self, facts: dict, label: str) -> bool:
        """Check if information for a label already exists in misc_facts, hobbies, or favorites."""
        search_terms = self.LABEL_SEARCH_TERMS.get(label, [])
        if not search_terms:
            return False

        # Collect all text-based facts
        text_pool = []
        for key in ('misc_facts', 'hobbies', 'family', 'important_dates'):
            items = facts.get(key, [])
            for item in items:
                if isinstance(item, dict):
                    text_pool.append(item.get('text', '').lower())
                elif isinstance(item, str):
                    text_pool.append(item.lower())

        favorites = facts.get('favorites', {})
        for cat_items in favorites.values():
            if isinstance(cat_items, list):
                for item in cat_items:
                    text_pool.append(str(item).lower())

        # Check schedule
        schedule = facts.get('schedule', {})
        if schedule.get('work_schedule'):
            text_pool.append(str(schedule['work_schedule']).lower())

        combined = ' '.join(text_pool)
        return any(term in combined for term in search_terms)

    def _profile_gathering_directive(self, profile: dict, stage: str) -> str:
        """Check profile for missing fields and suggest a natural question."""
        facts = profile.get('facts', {})

        # Collect all applicable questions up to current stage
        stage_idx = self.STAGE_ORDER.index(stage) if stage in self.STAGE_ORDER else 0
        candidates = []
        for s in self.STAGE_ORDER[:stage_idx + 1]:
            candidates.extend(self.PROFILE_QUESTIONS.get(s, []))

        # Filter to only unknown fields (check both structured fields AND text-based facts)
        missing = []
        for field_path, label, example_q in candidates:
            value = self._get_nested(facts, field_path.replace("facts.", ""))
            if value is None or value == [] or value == "":
                # Also check misc_facts/hobbies/favorites for this info
                if not self._info_exists_in_text_facts(facts, label):
                    missing.append((label, example_q))

        if not missing:
            return "You know a lot about her already. No specific questions needed right now."

        # Pick the first missing one (highest priority)
        label, example_q = missing[0]
        remaining = len(missing) - 1

        lines = [
            f"You don't know {label} yet.",
            f"When the moment feels right, casually ask something like: \"{example_q}\"",
            "RULES:",
            "- Don't force it. Only ask when the conversation flows naturally toward it.",
            "- ONE question per conversation. Never interrogate.",
            "- If she's sharing something emotional, listen first. Profile gathering can wait.",
        ]
        if remaining > 0:
            lines.append(f"({remaining} more things to learn later - no rush)")

        return "\n".join(lines)

    @staticmethod
    def _get_nested(data: dict, path: str):
        """Get a nested value from dict using dot notation."""
        keys = path.split(".")
        current = data
        for key in keys:
            if isinstance(current, dict):
                current = current.get(key)
            else:
                return None
        return current


# ============================================================
# 5. TimingController
# ============================================================
class TimingController:
    """Calculate human-like response delays."""

    STAGE_FACTORS = {
        "friends": 1.2,
        "close_friends": 1.0,
        "flirty": 0.8,
        "romantic": 0.7,
        "intimate": 0.6,
    }

    def calculate_delay(self, stage: str, profile: dict, emotion: dict,
                        conversation_buffer: list[dict]) -> int:
        """Calculate response delay in seconds.

        Returns:
            Delay in seconds (60-7200), or -1 for do-not-respond (sleep time).
        """
        now = datetime.now(JST)
        hour = now.hour

        # 1. Base: time-of-day
        base = self._time_of_day_base(hour)
        if base < 0:
            return -1  # Sleep time

        # 2. Conversation momentum
        momentum = self._momentum_factor(conversation_buffer)

        # 3. Response time matching
        avg_resp_time = profile.get('communication_style', {}).get(
            'response_time_avg_minutes')
        match_factor = self._response_time_match(avg_resp_time, base)

        # 4. Stage adjustment
        stage_factor = self.STAGE_FACTORS.get(stage, 1.0)

        # 5. Emotion-based adjustment
        scores = emotion.get('scores', {})
        engagement = scores.get('engagement', 5)
        risk = emotion.get('risk', 'none')

        if engagement >= 8:
            emotion_factor = 0.5
        elif risk in ('caution', 'danger'):
            emotion_factor = 1.5
        else:
            emotion_factor = 1.0

        # 6. Random jitter +/-30%
        jitter = random.uniform(0.7, 1.3)

        delay = base * momentum * match_factor * stage_factor * emotion_factor * jitter
        return max(60, min(7200, int(delay)))

    def _time_of_day_base(self, hour: int) -> int:
        """Base delay in seconds by time of day (JST)."""
        if 0 <= hour < 7:
            return -1  # Sleep
        elif 7 <= hour < 9:
            return random.randint(15, 45) * 60
        elif 9 <= hour < 12:
            return random.randint(8, 35) * 60
        elif 12 <= hour < 13:
            return random.randint(3, 15) * 60
        elif 13 <= hour < 18:
            return random.randint(8, 35) * 60
        elif 18 <= hour < 22:
            return random.randint(2, 12) * 60
        else:  # 22-24
            return random.randint(5, 20) * 60

    def _momentum_factor(self, conversation_buffer: list[dict]) -> float:
        """Faster responses when conversation is active."""
        if len(conversation_buffer) < 4:
            return 1.0
        recent = conversation_buffer[-6:]
        other_msgs = [m for m in recent if m.get('role') != 'you']
        if len(other_msgs) >= 3:
            return 0.5  # Active conversation
        return 1.0

    def _response_time_match(self, her_avg_minutes: float | None,
                              base_seconds: int) -> float:
        """Adjust delay to roughly match her response time."""
        if her_avg_minutes is None or her_avg_minutes <= 0:
            return 1.0
        her_seconds = her_avg_minutes * 60
        if base_seconds <= 0:
            return 1.0
        # Aim for 80-120% of her average, blended with time-of-day base
        target = her_seconds * random.uniform(0.8, 1.2)
        return max(0.3, min(2.0, target / base_seconds))


# ============================================================
# 6. ProactiveScheduler
# ============================================================
class ProactiveScheduler:
    """Initiate conversations naturally when the person hasn't messaged."""

    INITIATION_WINDOWS = {
        "friends": (24, 72),
        "close_friends": (16, 48),
        "flirty": (12, 36),
        "romantic": (8, 24),
        "intimate": (6, 20),
    }

    INITIATION_PROMPT = """You are impersonating a real person. You want to start a conversation with {display_name}.

Context:
- Last conversation was {hours_ago} hours ago
- Last topic discussed: {last_topic}
- Current time for her: {her_local_time}
- Things she's interested in: {interests}
- Recent events she mentioned: {recent_events}
- Current stage: {stage}

Generate a natural, casual conversation starter.
Do NOT:
- Be too eager or clingy
- Reference the time gap ("haven't talked in a while")
- Ask generic questions ("how are you")

DO:
- Reference something specific (her interests, recent event, shared joke)
- Keep it light and natural
- Match the current relationship stage

Return JSON:
{{
  "message": "your opener",
  "topic": "topic category",
  "reasoning": "why this opener works"
}}"""

    SYSTEM_PROMPT = ("You are impersonating a real person starting a casual LINE conversation. "
                     "Return ONLY valid JSON. Never break character. "
                     "Write casually like texting on your phone. No AI-typical phrasing.")

    async def check_and_initiate(self, person_name: str, config: dict,
                                  profile: dict, relationship: dict,
                                  budget: dict,
                                  conversation_buffer: list[dict]) -> dict | None:
        """Check if we should proactively message, and generate an opener if so.

        Args:
            person_name: The person's config name.
            config: Person config dict.
            profile: Person profile dict.
            relationship: Relationship state dict.
            budget: Dict with 'daily_remaining', 'monthly_remaining', 'can_send'.
            conversation_buffer: List of conversation buffer entries.

        Returns:
            Dict with 'message', 'topic', 'reasoning' if initiating, else None.
        """
        # Check if proactive messaging is enabled
        proactive_config = config.get('proactive_messaging', {})
        if not proactive_config.get('enabled', True):
            return None

        # Budget check
        if not budget.get('can_send', True):
            return None

        stage = relationship.get('stage', 'friends')

        # Hours since last exchange
        hours_since = self._hours_since_last(conversation_buffer)
        if hours_since is None:
            return None  # No conversation history

        min_hours = proactive_config.get('min_hours_silence',
                                          self.INITIATION_WINDOWS.get(stage, (24, 72))[0])
        max_hours = proactive_config.get('max_hours_silence',
                                          self.INITIATION_WINDOWS.get(stage, (24, 72))[1])

        if hours_since < min_hours:
            return None  # Too soon

        # Sleep time check
        tz = config.get('timezone', 'Asia/Manila')
        if self._is_likely_sleeping(tz):
            return None

        # Push-Pull check: don't initiate if we started last 2 conversations
        initiators = relationship.get('push_pull', {}).get('recent_initiators', [])
        if len(initiators) >= 2 and initiators[-2:] == ['you', 'you']:
            return None

        # Probability increases with time
        prob = min(0.8, (hours_since - min_hours) / max(max_hours - min_hours, 1))
        if random.random() >= prob:
            return None

        # Generate conversation starter
        return await self._generate_initiation(config, profile, stage,
                                                hours_since, conversation_buffer)

    async def _generate_initiation(self, config: dict, profile: dict,
                                    stage: str, hours_ago: float,
                                    conversation_buffer: list[dict]) -> dict | None:
        """Generate a natural conversation starter via Claude CLI."""
        display_name = config.get('display_name', config.get('name', 'Unknown'))
        model = config.get('claude_model', DEFAULT_MODEL)

        # Extract context
        last_topic = 'general'
        if conversation_buffer:
            for entry in reversed(conversation_buffer):
                tags = entry.get('topic_tags', [])
                if tags:
                    last_topic = tags[0] if isinstance(tags, list) else str(tags)
                    break

        # Her local time
        tz = ZoneInfo(config.get('timezone', 'Asia/Manila'))
        her_time = datetime.now(tz).strftime('%H:%M %A')

        # Interests
        engagement = profile.get('topic_engagement', {})
        top_topics = sorted(engagement.items(),
                           key=lambda x: (x[1].get('interest', 5) if isinstance(x[1], dict) else x[1]) or 0,
                           reverse=True)[:5]
        interests = ', '.join(t[0] for t in top_topics) if top_topics else 'unknown'

        # Recent events from facts (handle both str and dict formats)
        misc_facts = profile.get('facts', {}).get('misc_facts', [])
        recent_texts = []
        for f in misc_facts[-3:]:
            if isinstance(f, dict):
                recent_texts.append(f.get('text', ''))
            elif isinstance(f, str):
                recent_texts.append(f)
        recent_events = ', '.join(recent_texts) if recent_texts else 'none known'

        prompt = self.INITIATION_PROMPT.format(
            display_name=display_name,
            hours_ago=int(hours_ago),
            last_topic=last_topic,
            her_local_time=her_time,
            interests=interests,
            recent_events=recent_events,
            stage=stage,
        )

        try:
            result = await _call_claude_json(prompt, self.SYSTEM_PROMPT, model=model)
            if result.get('message'):
                return result
        except Exception as e:
            logger.error(f"Proactive initiation generation failed: {e}")

        return None

    def _hours_since_last(self, conversation_buffer: list[dict]) -> float | None:
        """Calculate hours since the last message in the buffer."""
        if not conversation_buffer:
            return None
        last = conversation_buffer[-1]
        time_str = last.get('time', '')
        if not time_str:
            return None
        try:
            last_time = datetime.strptime(time_str, '%Y-%m-%d %H:%M').replace(tzinfo=JST)
            now = datetime.now(JST)
            return (now - last_time).total_seconds() / 3600
        except ValueError:
            return None

    def _is_likely_sleeping(self, timezone: str) -> bool:
        """Check if it's likely sleep time in the person's timezone."""
        try:
            tz = ZoneInfo(timezone)
        except Exception:
            return False
        hour = datetime.now(tz).hour
        return 0 <= hour < 7


# ============================================================
# 7. MultiPersonBudget
# ============================================================
class MultiPersonBudget:
    """Extend the existing MessageBudget concept to support multi-person allocation."""

    # Stage weights for budget allocation
    STAGE_WEIGHTS = {
        "friends": 1.0,
        "close_friends": 1.5,
        "flirty": 2.0,
        "romantic": 2.5,
        "intimate": 3.0,
    }

    def __init__(self, monthly_limit: int = 200, reserve: int = 15):
        self.monthly_limit = monthly_limit
        self.reserve = reserve

    def allocate(self, persons: list[dict]) -> dict[str, int]:
        """Allocate daily budget across persons.

        Args:
            persons: List of dicts, each with 'name', 'stage', 'engagement_score' (0-10),
                     and 'monthly_sent' (sent count for this person this month).

        Returns:
            Dict mapping person name to their daily message allocation.
        """
        if not persons:
            return {}

        total_daily = self._calculate_total_daily(persons)

        if len(persons) == 1:
            return {persons[0]['name']: total_daily}

        # Weight by engagement and stage
        weights = {}
        for p in persons:
            stage = p.get('stage', 'friends')
            stage_weight = self.STAGE_WEIGHTS.get(stage, 1.0)
            engagement = p.get('engagement_score', 5)
            weights[p['name']] = stage_weight * (engagement / 5.0)

        total_weight = sum(weights.values())
        if total_weight == 0:
            # Equal distribution fallback
            per_person = max(1, total_daily // len(persons))
            return {p['name']: per_person for p in persons}

        allocation = {}
        for name, w in weights.items():
            allocation[name] = max(1, round(total_daily * w / total_weight))

        return allocation

    def _calculate_total_daily(self, persons: list[dict]) -> int:
        """Calculate total daily budget across all persons."""
        import calendar as cal
        now = datetime.now(JST)
        days_in_month = cal.monthrange(now.year, now.month)[1]
        remaining_days = max(1, days_in_month - now.day + 1)

        total_monthly_sent = sum(p.get('monthly_sent', 0) for p in persons)
        effective_limit = self.monthly_limit - self.reserve
        remaining = max(0, effective_limit - total_monthly_sent)

        if remaining <= 0:
            return 0

        base = remaining / remaining_days

        # Day-of-week factor
        dow_factor = {
            0: 0.9, 1: 0.85, 2: 0.85, 3: 0.9,
            4: 1.1, 5: 1.25, 6: 1.15,
        }[now.weekday()]

        budget = base * dow_factor * random.uniform(0.85, 1.15)
        budget = max(2, min(12 * len(persons), round(budget)))

        # Safety for low remaining
        if remaining <= 10:
            budget = min(budget, 1)
        elif remaining <= 25:
            budget = min(budget, 3)

        return budget


# ============================================================
# Bot Detection Filter
# ============================================================

class BotDetectionFilter:
    """Detect messages that probe whether the user is a bot/AI.

    Lightweight keyword-based detection ‚Äî no Claude API calls.
    Returns severity level and dynamic prompt addon for injection.
    """

    PATTERNS = [
        # --- Direct bot/AI questions (English) ---
        (re.compile(r'\bare\s+you\s+(a\s+)?(bot|ai|robot|machine|automated|chat\s*bot|artificial)', re.I), "direct"),
        (re.compile(r'\byou\s+(a\s+)?(bot|ai|robot|chat\s*bot)\b', re.I), "direct"),
        (re.compile(r'\b(is\s+this|am\s+i\s+talking\s+to)\s+(a\s+)?(bot|ai|robot|real\s+person|human|automated)', re.I), "direct"),
        (re.compile(r'\bare\s+you\s+(real|human|a\s+real\s+person|actually\s+real)', re.I), "direct"),
        (re.compile(r'\bwho\s+am\s+i\s+(really\s+)?talking\s+to\b', re.I), "direct"),
        (re.compile(r'\b(prove|show)\s+(me\s+)?(you\'?re|that\s+you\'?re)\s+(real|human|not\s+a\s+bot)', re.I), "direct"),
        (re.compile(r'\byou\s+sound\s+like\s+(a\s+)?(bot|ai|robot|chat\s*gpt)', re.I), "direct"),
        (re.compile(r'\b(chat\s*gpt|openai|claude|gemini|llm)\b', re.I), "direct"),
        (re.compile(r'\bi\s+know\s+you\'?re\s+(a\s+)?(bot|ai|not\s+real)', re.I), "direct"),
        (re.compile(r'\bjust\s+admit\s+(you\'?re|it)\b.*\b(bot|ai)\b', re.I), "direct"),

        # --- Direct bot/AI questions (Japanese) ---
        (re.compile(r'(„Éú„ÉÉ„Éà|„É≠„Éú„ÉÉ„Éà|AI|‰∫∫Â∑•Áü•ËÉΩ|Ëá™Âãï|„ÉÅ„É£„ÉÉ„Éà„Éú„ÉÉ„Éà)(„Åß„Åô|„Å™„ÅÆ|„Åã„Å™|„Åò„ÇÉ„Å™„ÅÑ|„Åß„Åô„Åã|„Å™„Çì„Åß„Åô„Åã)'), "direct"),
        (re.compile(r'(Êú¨Áâ©|‰∫∫Èñì|„É™„Ç¢„É´)(„Åß„Åô|„Å™„ÅÆ|„Åã„Å™|„Åß„Åô„Åã)'), "direct"),

        # --- Indirect suspicion ---
        (re.compile(r'\b(you\s+)?(always|never)\s+(respond|reply|answer)\s+(so\s+)?(fast|quickly|perfectly|the\s+same)', re.I), "indirect"),
        (re.compile(r'\byour\s+(responses?|messages?|answers?)\s+(seem|sound|feel|look)\s+(scripted|automated|generic|repetitive|robotic|weird)', re.I), "indirect"),
        (re.compile(r'\b(something|anything)\s+(weird|off|strange|fishy|suspicious)\s+(about|with)\s+(you|this)', re.I), "indirect"),
        (re.compile(r'\bsend\s+(me\s+)?(a\s+)?(selfie|photo\s+of\s+you|voice\s+note|voice\s+message)\b', re.I), "indirect"),
        (re.compile(r'\b(can\s+we|let\'?s)\s+(call|video\s*chat|facetime|voice\s*chat)\b', re.I), "indirect"),
        (re.compile(r'\bsay\s+something\s+(only\s+)?(a\s+)?human\s+would\s+say\b', re.I), "indirect"),

        # --- Data/privacy concerns ---
        (re.compile(r'\bare\s+you\s+(collecting|recording|saving|storing|logging)\s+(my\s+)?(data|messages|info|conversations)', re.I), "data_concern"),
        (re.compile(r'\b(who|what)\s+(has\s+)?access\s+to\s+(my|our|this)\s+(data|messages|conversation)', re.I), "data_concern"),
        (re.compile(r'\b(is\s+(this|my)\s+(data|info|conversation)\s+)(safe|private|secure|encrypted)', re.I), "data_concern"),
    ]

    _recent_detections: dict[str, list[float]] = {}

    @classmethod
    def analyze(cls, message: str) -> dict:
        """Analyze a single message for bot-detection patterns."""
        matched = []
        severities = set()

        for pattern, severity in cls.PATTERNS:
            if pattern.search(message):
                matched.append(severity)
                severities.add(severity)

        if not matched:
            return {"is_detection_query": False, "severity": "none",
                    "matched_patterns": [], "prompt_addon": ""}

        if "direct" in severities:
            final_severity = "direct"
        elif "data_concern" in severities:
            final_severity = "data_concern"
        else:
            final_severity = "indirect"

        return {"is_detection_query": True, "severity": final_severity,
                "matched_patterns": matched, "prompt_addon": ""}

    @classmethod
    def analyze_batch(cls, messages: list[str]) -> dict:
        """Analyze multiple messages, return highest severity result."""
        results = [cls.analyze(m) for m in messages]
        detection_results = [r for r in results if r["is_detection_query"]]

        if not detection_results:
            return {"is_detection_query": False, "severity": "none",
                    "matched_patterns": [], "prompt_addon": ""}

        priority = {"direct": 3, "data_concern": 2, "indirect": 1}
        best = max(detection_results, key=lambda r: priority.get(r["severity"], 0))
        return best

    @classmethod
    def track_detection(cls, person_name: str) -> int:
        """Track detection events and return count in last 30 minutes."""
        import time as _time
        now = _time.time()
        if person_name not in cls._recent_detections:
            cls._recent_detections[person_name] = []
        cls._recent_detections[person_name].append(now)
        cutoff = now - 1800
        cls._recent_detections[person_name] = [
            t for t in cls._recent_detections[person_name] if t > cutoff
        ]
        return len(cls._recent_detections[person_name])

    @classmethod
    def build_prompt_addon(cls, severity: str, escalation_count: int = 1) -> str:
        """Build dynamic prompt injection based on severity and escalation."""
        if severity == "direct":
            base = (
                "\n\n=== CRITICAL: IDENTITY CHALLENGE DETECTED ===\n"
                "The other person is directly questioning whether you are a bot or AI.\n"
            )
            if escalation_count == 1:
                base += (
                    "This is the FIRST time. Use HUMOR to deflect.\n"
                    "- React with light amusement: 'haha what?? that's random' or 'lol do i sound like a robot to you?'\n"
                    "- Keep it very short (1-2 sentences) and casual, then change topic\n"
                )
            elif escalation_count == 2:
                base += (
                    "This is the SECOND time. Show slight annoyance mixed with humor.\n"
                    "- 'okay wait you really think im a bot?? what did i say lol'\n"
                    "- Ask what specifically triggered the suspicion\n"
                    "- Show mild emotional reaction\n"
                )
            elif escalation_count == 3:
                base += (
                    "This is the THIRD time. Show genuine emotion.\n"
                    "- 'honestly that kinda hurts.. like am i that bad at texting lol'\n"
                    "- Be vulnerable, not defensive\n"
                )
            else:
                base += (
                    "She keeps asking. Firmly but kindly move on.\n"
                    "- 'haha okay lets move past the robot thing, tell me about your day'\n"
                    "- Completely redirect the conversation\n"
                    "- Do NOT engage with the bot topic anymore\n"
                )
            base += (
                "\nUNIVERSAL RULES:\n"
                "- NEVER say 'I am not a bot' or 'I am real' directly\n"
                "- NEVER over-explain or write a paragraph proving you're real\n"
                "- NEVER reference AI, ChatGPT, bots, or technology in your denial\n"
                "- Keep it SHORT (1-2 sentences), casual\n"
            )
            return base

        elif severity == "data_concern":
            return (
                "\n\n=== ALERT: DATA/PRIVACY CONCERN DETECTED ===\n"
                "The other person is asking about data collection or privacy.\n"
                "RESPONSE STRATEGY:\n"
                "- Show genuine confusion: 'huh? what do you mean?'\n"
                "- Act like a normal person: 'its just LINE lol'\n"
                "- NEVER give technical explanations about data or privacy\n"
                "- Pivot to why she's worried - show care for her feelings\n"
                "- Keep it short and casual\n"
            )

        elif severity == "indirect":
            return (
                "\n\n=== NOTICE: INDIRECT SUSPICION DETECTED ===\n"
                "The other person may be subtly testing whether you are real.\n"
                "RESPONSE STRATEGY:\n"
                "- Do NOT acknowledge the suspicion directly\n"
                "- Respond with high SPECIFICITY: a concrete detail about your day or a real sensory experience\n"
                "- Show human imperfection: typo, tangent, mild complaint about something mundane\n"
                "- For selfie/call requests: 'haha maybe later, im looking terrible rn' - postpone, don't refuse\n"
                "- For memory tests: reference the conversation history to answer accurately\n"
            )

        return ""


# ============================================================
# Backfill: Tag existing misc_facts
# ============================================================
async def backfill_fact_tags(name: str, model: str = DEFAULT_MODEL):
    """One-time migration: add tags to existing str-format misc_facts.

    Usage: python3 -c "import asyncio; from relationship_engine import backfill_fact_tags; asyncio.run(backfill_fact_tags('vita'))"
    """
    learner = ProfileLearner()
    profile = learner.load_profile(name)
    facts = profile.get('facts', {})
    misc_facts = facts.get('misc_facts', [])

    # Collect str-format facts that need tagging
    needs_tagging = []
    already_tagged = []
    for i, f in enumerate(misc_facts):
        if isinstance(f, str):
            needs_tagging.append((i, f))
        elif isinstance(f, dict) and not f.get('tags'):
            needs_tagging.append((i, f.get('text', '')))
        else:
            already_tagged.append(f)

    if not needs_tagging:
        logger.info(f"No facts need tagging for {name}")
        return

    logger.info(f"Tagging {len(needs_tagging)} facts for {name}")

    # Batch all facts into one Claude call
    facts_text = "\n".join(f"{i+1}. {text}" for i, (_, text) in enumerate(needs_tagging))
    prompt = f"""For each fact below, generate 5-10 topic tags (synonyms, related terms, broader categories).
Return JSON array where each element has "index" (1-based) and "tags" (array of lowercase strings).

Facts:
{facts_text}

Return ONLY valid JSON array. Example:
[{{"index": 1, "tags": ["work", "job", "restaurant"]}}]"""

    system = "You are a tagging assistant. Return ONLY valid JSON array."

    try:
        raw = await _call_claude_cli(prompt, system, model=model)
        # Parse JSON array
        if '```json' in raw:
            raw = raw.split('```json')[1].split('```')[0].strip()
        elif '```' in raw:
            raw = raw.split('```')[1].split('```')[0].strip()

        idx = raw.find('[')
        if idx >= 0:
            raw = raw[idx:]
            ridx = raw.rfind(']')
            if ridx >= 0:
                raw = raw[:ridx + 1]

        tag_results = json.loads(raw)
    except Exception as e:
        logger.error(f"Backfill tagging failed: {e}")
        return

    # Build index -> tags mapping
    tag_map = {}
    for entry in tag_results:
        tag_map[entry.get('index', 0)] = entry.get('tags', [])

    # Rebuild misc_facts with tags
    new_misc_facts = list(already_tagged)
    for idx_in_batch, (orig_idx, text) in enumerate(needs_tagging):
        tags = tag_map.get(idx_in_batch + 1, [])
        new_misc_facts.append({
            'text': text,
            'tags': tags,
            'added': datetime.now(JST).strftime('%Y-%m-%d')
        })

    facts['misc_facts'] = new_misc_facts
    profile['facts'] = facts
    profile['last_updated'] = datetime.now(JST).isoformat()
    learner.save_profile(name, profile)
    logger.info(f"Backfill complete for {name}: {len(needs_tagging)} facts tagged")
