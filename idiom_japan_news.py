#!/usr/bin/env python3
"""
æ¯æ™‚Idiomã‚µãƒ¼ãƒãƒ¼ã®Google News RSSã‚’ä½¿ç”¨ã—ã¦å›½å†…æƒ…å‹¢ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã€ŒğŸ‡¯ğŸ‡µï½œå›½å†…æƒ…å‹¢ã€ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã«æŠ•ç¨¿

Google News RSSã‚’ä½¿ç”¨ï¼ˆå®Œå…¨ç„¡æ–™ãƒ»API keyä¸è¦ï¼‰
ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ãƒãƒ£ãƒ³ãƒãƒ«ID: 1448493374863573044
"""

import os
import asyncio
import json
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
import discord
from discord.ext import commands
import aiohttp
import feedparser
import re
from html import unescape

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿
env_vars = {}
env_path = '/Users/minamitakeshi/discord-mcp-server/.env'
if os.path.exists(env_path):
    with open(env_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                env_vars[key] = value

DISCORD_TOKEN = env_vars.get("DISCORD_TOKEN")

# ğŸ‡¯ğŸ‡µï½œå›½å†…æƒ…å‹¢ ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆIdiomã‚µãƒ¼ãƒãƒ¼ï¼‰
FORUM_ID = 1448493374863573044

# æŠ•ç¨¿å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆIdiomå°‚ç”¨ï¼‰
HISTORY_FILE = '/Users/minamitakeshi/discord-mcp-server/idiom_japan_news_history.json'

# Google News RSS URLï¼ˆå›½å†…æƒ…å‹¢é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ - ç¶²ç¾…çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰
# ã‚«ãƒ†ã‚´ãƒª: æ”¿æ²»ã€æ”¿ç­–ã€çµŒæ¸ˆã€ç¤¾ä¼šã€åœ°æ–¹
GOOGLE_NEWS_RSS = 'https://news.google.com/rss/search?q=å›½ä¼š OR å†…é–£ OR é¦–ç›¸ OR å®˜é‚¸ OR ä¸å…š OR é‡å…š OR è‡ªæ°‘å…š OR ç«‹æ†²æ°‘ä¸»å…š OR æ”¿æ¨© OR é¸æŒ™ OR è¡†è­°é™¢ OR å‚è­°é™¢ OR äºˆç®—æ¡ˆ OR æ³•æ¡ˆ OR é–£è­°æ±ºå®š OR è¦åˆ¶æ”¹é© OR å°‘å­åŒ–å¯¾ç­– OR ç¤¾ä¼šä¿éšœ OR å¹´é‡‘ OR åŒ»ç™‚åˆ¶åº¦ OR ä»‹è­· OR æ—¥éŠ€ OR é‡‘èæ”¿ç­– OR å††å®‰ OR å††é«˜ OR ç‰©ä¾¡é«˜ OR ã‚¤ãƒ³ãƒ•ãƒ¬ OR è³ƒä¸Šã’ OR æ™¯æ°— OR ç½å®³ OR åœ°éœ‡ OR å°é¢¨ OR äº‹ä»¶ OR äº‹æ•… OR è£åˆ¤ OR åˆ¤æ±º OR çŸ¥äº‹ OR å¸‚é•· OR åœ°æ–¹è‡ªæ²» OR åœ°æ–¹å‰µç”Ÿ OR ãƒã‚¤ãƒŠãƒ³ãƒãƒ¼ OR ç¨åˆ¶æ”¹æ­£ OR é˜²è¡›è²»&hl=ja&gl=JP&ceid=JP:ja'

# ä¿¡é ¼ã§ãã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢åã®ãƒªã‚¹ãƒˆ
TRUSTED_MEDIA_NAMES = [
    'æ—¥æœ¬çµŒæ¸ˆæ–°è',
    'æ—¥çµŒ',
    'æœæ—¥æ–°è',
    'èª­å£²æ–°è',
    'æ¯æ—¥æ–°è',
    'ç”£çµŒæ–°è',
    'æ±äº¬æ–°è',
    'åŒ—æµ·é“æ–°è',
    'ä¸­æ—¥æ–°è',
    'è¥¿æ—¥æœ¬æ–°è',
    'æ™‚äº‹é€šä¿¡',
    'å…±åŒé€šä¿¡',
    'NHK',
    'TBS',
    'ãƒ†ãƒ¬ãƒ“æœæ—¥',
    'æ—¥æœ¬ãƒ†ãƒ¬ãƒ“',
    'ãƒ•ã‚¸ãƒ†ãƒ¬ãƒ“',
    'ãƒ†ãƒ¬ãƒ“æ±äº¬',
    'æ±æ´‹çµŒæ¸ˆ',
    'ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰',
    'Bloomberg',
    'ãƒ–ãƒ«ãƒ¼ãƒ ãƒãƒ¼ã‚°',
    'Reuters',
    'ãƒ­ã‚¤ã‚¿ãƒ¼',
    'WEDGE',
    'JBpress',
    'ç¾ä»£ãƒ“ã‚¸ãƒã‚¹',
    'Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹',
    'PR TIMES',
    'æ–‡æ˜¥ã‚ªãƒ³ãƒ©ã‚¤ãƒ³',
    'æ–°æ½®',
    'AERA',
    'ãƒ—ãƒ¬ã‚¸ãƒ‡ãƒ³ãƒˆ',
]

# BotåˆæœŸåŒ–
intents = discord.Intents.default()
intents.guilds = True
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)


def load_history():
    """éå»ã®æŠ•ç¨¿å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ï¼ˆç›´è¿‘30æ—¥åˆ†ï¼‰"""
    if not os.path.exists(HISTORY_FILE):
        return []

    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            history = json.load(f)

        now = datetime.now(ZoneInfo('Asia/Tokyo'))
        cutoff_date = (now - timedelta(days=30)).isoformat()
        history = [item for item in history if item['date'] >= cutoff_date]

        return history
    except:
        return []


def save_history(history, new_items):
    """æŠ•ç¨¿å±¥æ­´ã‚’ä¿å­˜"""
    today = datetime.now(ZoneInfo('Asia/Tokyo')).isoformat()

    for item in new_items:
        history.append({
            'date': today,
            'title': item['title'],
            'url': item['url']
        })

    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def is_trusted_source(title, summary):
    """ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯è¦ç´„ã«ä¿¡é ¼ã§ãã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    combined_text = f"{title} {summary}"
    for media_name in TRUSTED_MEDIA_NAMES:
        if media_name in combined_text:
            return True
    return False


def is_duplicate(title, url, history):
    """å±¥æ­´ã¨é‡è¤‡ã—ã¦ã„ã‚‹ã‹ç¢ºèª"""
    for item in history:
        if item['url'] == url:
            return True
        title_words = set(title.split())
        history_words = set(item['title'].split())
        if title_words and history_words:
            similarity = len(title_words & history_words) / len(title_words | history_words)
            if similarity > 0.8:
                return True
    return False


async def fetch_google_news():
    """Google News RSSã‹ã‚‰æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(GOOGLE_NEWS_RSS, timeout=aiohttp.ClientTimeout(total=10)) as response:
                if response.status == 200:
                    rss_content = await response.text()
                    return rss_content
                else:
                    print(f'RSSå–å¾—ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status}')
                    return None
    except Exception as e:
        print(f'RSSå–å¾—ã‚¨ãƒ©ãƒ¼: {e}')
        return None


def remove_html_tags(text):
    """HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™"""
    if not text:
        return ''
    text = unescape(text)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    return text


def parse_rss(rss_content):
    """RSSã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    feed = feedparser.parse(rss_content)
    news_list = []

    for entry in feed.entries[:50]:
        title = entry.get('title', '')
        url = entry.get('link', '')
        summary = entry.get('summary', entry.get('description', ''))
        published = entry.get('published', '')

        title = remove_html_tags(title)
        summary = remove_html_tags(summary)

        if url:
            news_list.append({
                'title': title,
                'summary': summary[:200] if summary else 'ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¦‚è¦ãªã—',
                'url': url,
                'published': published
            })

    return news_list


async def verify_url(url):
    """URLãŒå®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹æ¤œè¨¼ã—ã€ã‚ªãƒªã‚¸ãƒŠãƒ«URLã‚’è¿”ã™"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.head(url, timeout=aiohttp.ClientTimeout(total=5), allow_redirects=True) as response:
                return (response.status < 400, str(response.url))
    except:
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=5), allow_redirects=True) as response:
                    return (response.status < 400, str(response.url))
        except:
            return (False, url)


@bot.event
async def on_ready():
    """Botèµ·å‹•æ™‚ã«å®Ÿè¡Œ"""
    print(f'Botèµ·å‹•: {bot.user}')

    try:
        forum = bot.get_channel(FORUM_ID)
        if not forum:
            print(f'ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆID: {FORUM_ID}ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            await bot.close()
            return

        print(f'ãƒ•ã‚©ãƒ¼ãƒ©ãƒ : {forum.name}')

        history = load_history()
        print(f'æŠ•ç¨¿å±¥æ­´: {len(history)}ä»¶')

        print('Google News RSSã‹ã‚‰å›½å†…æƒ…å‹¢ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...')
        rss_content = await fetch_google_news()

        if not rss_content:
            print('âŒ RSSå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ')
            await bot.close()
            return

        news_list = parse_rss(rss_content)
        print(f'RSSå–å¾—ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(news_list)}')

        if len(news_list) == 0:
            print('â„¹ï¸  ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
            await bot.close()
            return

        print('URLæ¤œè¨¼ï¼†ã‚ªãƒªã‚¸ãƒŠãƒ«URLå–å¾—ä¸­...')
        verified_news = []
        for news in news_list:
            is_valid, original_url = await verify_url(news['url'])
            if is_valid:
                news['url'] = original_url
                verified_news.append(news)

        if len(verified_news) == 0:
            print('âš ï¸  å…¨ã¦ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒURLæ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ')
            await bot.close()
            return

        print(f'æ¤œè¨¼æ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(verified_news)}')

        print('ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...')
        trusted_news = [news for news in verified_news if is_trusted_source(news['title'], news['summary'])]

        if len(trusted_news) == 0:
            print('â„¹ï¸  ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã‹ã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
            await bot.close()
            return

        print(f'ä¿¡é ¼ã§ãã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(trusted_news)}')

        print('é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...')
        unique_news = [news for news in trusted_news if not is_duplicate(news['title'], news['url'], history)]

        if len(unique_news) == 0:
            print('â„¹ï¸  æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“')
            await bot.close()
            return

        print(f'æ–°è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(unique_news)}')

        unique_news = unique_news[:2]
        print(f'æŠ•ç¨¿å¯¾è±¡: {len(unique_news)}ä»¶')

        now = datetime.now(ZoneInfo('Asia/Tokyo'))
        today = now.strftime('%Yå¹´%mæœˆ%dæ—¥')
        posted_count = 0

        for i, news in enumerate(unique_news, 1):
            thread_title = f"{news['title']}"
            thread_content = f"{news['summary']}\n\n{news['url']}"

            print(f'ã‚¹ãƒ¬ãƒƒãƒ‰ä½œæˆä¸­ ({i}/{len(unique_news)}): {thread_title[:50]}...')

            thread = await forum.create_thread(
                name=thread_title[:100],
                content=thread_content
            )

            print(f'  âœ… æŠ•ç¨¿å®Œäº†: {thread.thread.jump_url}')
            posted_count += 1

            await asyncio.sleep(2)

        print(f'\nâœ… å…¨{posted_count}ä»¶ã®æŠ•ç¨¿å®Œäº†')

        save_history(history, unique_news)
        print('æŠ•ç¨¿å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ')

        os.system(f'osascript -e \'display notification "{today}ã®å›½å†…æƒ…å‹¢ãƒ‹ãƒ¥ãƒ¼ã‚¹ {posted_count}ä»¶ã‚’Idiomã«æŠ•ç¨¿ã—ã¾ã—ãŸ" with title "Idiom å›½å†…æƒ…å‹¢ãƒ‹ãƒ¥ãƒ¼ã‚¹"\'')

    except Exception as e:
        print(f'ã‚¨ãƒ©ãƒ¼: {e}')
        import traceback
        traceback.print_exc()

    await bot.close()


if __name__ == "__main__":
    bot.run(DISCORD_TOKEN)
